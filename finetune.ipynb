{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================WARNING: DEPRECATED!==============================\n",
      "WARNING! This version of bitsandbytes is deprecated. Please switch to `pip install bitsandbytes` and the new repo: https://github.com/TimDettmers/bitsandbytes\n",
      "==============================WARNING: DEPRECATED!==============================\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "import wandb\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import pandas as pd\n",
    "import transformers\n",
    "\n",
    "from custom_datasets import PromptDataset\n",
    "from gpt_quant_modules import GPTJBlock, GPTJForCausalLM\n",
    "from gpt_finetuner import FinetunerConfig, GPTJ8bitFineTuner\n",
    "from finetuning_utils import add_all_adapters, add_attention_adapters\n",
    "\n",
    "transformers.models.gptj.modeling_gptj.GPTJBlock = GPTJBlock \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The article on [Medium](https://medium.com/@vitaley.grechachin/how-to-train-a-capable-gpt-3-model-at-home-9c5b400ca7f), [Habr]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data\n",
    "## Required Data:\n",
    " * train and/or validation pandas DataFrame with two columns: prompt, completion\n",
    " * prompt + completion length must be less than 2048 tokens\n",
    " * For classification metrics completion must be 1 token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>offensive</td>\n",
       "      <td>RT @RAYCHIELOVESU: No &amp;#8220;@3rdeyechillin: T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>&amp;#8220;@__Black_Jesus: &amp;#8220;@lil_aerii: Happ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hate</td>\n",
       "      <td>&amp;#8220;@iamkrause: No need to thank me, killin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>offensive</td>\n",
       "      <td>RT @tr4pb0y: when the pussy so good &amp;amp; u fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>offensive</td>\n",
       "      <td>I talk to these bitches like I really do care.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text\n",
       "0  offensive  RT @RAYCHIELOVESU: No &#8220;@3rdeyechillin: T...\n",
       "1    neutral  &#8220;@__Black_Jesus: &#8220;@lil_aerii: Happ...\n",
       "2       hate  &#8220;@iamkrause: No need to thank me, killin...\n",
       "3  offensive  RT @tr4pb0y: when the pussy so good &amp; u fo...\n",
       "4  offensive     I talk to these bitches like I really do care."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example data\n",
    "\n",
    "train_df = pd.read_csv('./data/train.csv')\n",
    "val_df = pd.read_csv('./data/val.csv')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>RT @Black__Elvis: My favorite episode of Frien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hate</td>\n",
       "      <td>RT @TankTopshotta: A real nigga gone teach his...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hate</td>\n",
       "      <td>Shoot that nigga an his shorty bitch .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hate</td>\n",
       "      <td>@_XoXoKelsey_ hell naw fuck them bitches serve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@syd_renae okay cool then I'm not the only one...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "0  neutral  RT @Black__Elvis: My favorite episode of Frien...\n",
       "1     hate  RT @TankTopshotta: A real nigga gone teach his...\n",
       "2     hate             Shoot that nigga an his shorty bitch .\n",
       "3     hate  @_XoXoKelsey_ hell naw fuck them bitches serve...\n",
       "4  neutral  @syd_renae okay cool then I'm not the only one..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['label'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>completion</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>offensive</td>\n",
       "      <td>RT @RAYCHIELOVESU: No &amp;#8220;@3rdeyechillin: T...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Classify the following messages into one of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>&amp;#8220;@__Black_Jesus: &amp;#8220;@lil_aerii: Happ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Classify the following messages into one of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hate</td>\n",
       "      <td>&amp;#8220;@iamkrause: No need to thank me, killin...</td>\n",
       "      <td>hate</td>\n",
       "      <td>Classify the following messages into one of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>offensive</td>\n",
       "      <td>RT @tr4pb0y: when the pussy so good &amp;amp; u fo...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Classify the following messages into one of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>offensive</td>\n",
       "      <td>I talk to these bitches like I really do care.</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Classify the following messages into one of t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text  completion  \\\n",
       "0  offensive  RT @RAYCHIELOVESU: No &#8220;@3rdeyechillin: T...   offensive   \n",
       "1    neutral  &#8220;@__Black_Jesus: &#8220;@lil_aerii: Happ...     neutral   \n",
       "2       hate  &#8220;@iamkrause: No need to thank me, killin...        hate   \n",
       "3  offensive  RT @tr4pb0y: when the pussy so good &amp; u fo...   offensive   \n",
       "4  offensive     I talk to these bitches like I really do care.   offensive   \n",
       "\n",
       "                                              prompt  \n",
       "0   Classify the following messages into one of t...  \n",
       "1   Classify the following messages into one of t...  \n",
       "2   Classify the following messages into one of t...  \n",
       "3   Classify the following messages into one of t...  \n",
       "4   Classify the following messages into one of t...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can create prompt in 2 ways: instruction or raw text\n",
    "# For instruction propmpt we will use a human understandable textual instruction.\n",
    "# For raw prompt we will use raw text with special separator between propmpt and completion\n",
    "\n",
    "def create_instruction_prompt(text, all_labels):\n",
    "    prompt =  f''' Classify the following messages into one of the following categories: {','.join(all_labels)}\n",
    "\n",
    "Message: {text}\n",
    "\n",
    "Category:'''\n",
    "    return prompt\n",
    "\n",
    "def create_raw_prompt(text):\n",
    "    prompt =  f'''{text} /n/n###/n/n'''\n",
    "    return prompt\n",
    "\n",
    "# For classification task we need 1 token completion. The completion token must be in model vocabulary. \n",
    "# GPT tokenization required completion tokens started with whitespace.\n",
    "\n",
    "train_df['completion'] = train_df['label'].apply(lambda x: ' '+ x)\n",
    "val_df['completion'] = val_df['label'].apply(lambda x: ' ' + x)\n",
    "\n",
    "# instruction based prompt\n",
    "all_labels = set(train_df['completion'].unique())\n",
    "train_df['prompt'] = train_df['text'].apply(lambda x: create_instruction_prompt(x, all_labels))\n",
    "val_df['prompt'] = val_df['text'].apply(lambda x: create_instruction_prompt(x, all_labels))\n",
    "\n",
    "# # raw text based prompt\n",
    "# train_df['completion'] = train_df['text'].apply(create_raw_prompt)\n",
    "# val_df['completion'] = val_df['text'].apply(create_raw_prompt)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training and validation samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create torch Datasets with prepared finetuning samples\n",
    "\n",
    "# Load tokenizer and add padding token\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Define max_prompt_size. Used to pad short prompts and truncate large prompts. Need for batching or fitting VRAM.\n",
    "# We will take 0.99 quantile tokenized prompt length plus 1 token for completion. \n",
    "# Notice that we truncate only propmpt not completion.\n",
    "\n",
    "max_prompt_size = int(pd.Series(len(tokenizer.tokenize(e)) for e in (train_df['prompt'] + ' ' + train_df['completion'])).quantile(0.99)) + 1\n",
    "\n",
    "\n",
    "train_dataset = PromptDataset(train_df, tokenizer, max_prompt_len=max_prompt_size)\n",
    "val_dataset = PromptDataset(val_df, tokenizer, max_prompt_len=max_prompt_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 100\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvetka925\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97e89fc58037414b9682849caa2e04c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016670281149951432, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20230227_174705-pw0e5peu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/vetka925/GPT-J_finetune_hatetweets_instruct_final/runs/pw0e5peu\" target=\"_blank\">celestial-brook-8</a></strong> to <a href=\"https://wandb.ai/vetka925/GPT-J_finetune_hatetweets_instruct_final\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/vetka925/GPT-J_finetune_hatetweets_instruct_final\" target=\"_blank\">https://wandb.ai/vetka925/GPT-J_finetune_hatetweets_instruct_final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/vetka925/GPT-J_finetune_hatetweets_instruct_final/runs/pw0e5peu\" target=\"_blank\">https://wandb.ai/vetka925/GPT-J_finetune_hatetweets_instruct_final/runs/pw0e5peu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "lm_head Linear(in_features=4096, out_features=50400, bias=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vetka/Projects/torch_jupyter/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:467: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type            | Params\n",
      "------------------------------------------\n",
      "0 | model | GPTJForCausalLM | 5.2 M \n",
      "------------------------------------------\n",
      "5.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.2 M     Total params\n",
      "20.833    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce6cf19b6e449d6aac6b903e93a7b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vetka/Projects/torch_jupyter/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:488: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "/home/vetka/Projects/torch_jupyter/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/vetka/Projects/torch_jupyter/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a7c721749d425db66993cf2dae540f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "224a8922e3e845c0b426f4b5e59367af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f11290e6f074accad746e05c1863035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "020d3ea0df1c4dd99ae3e39438c7f8d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅█████████████</td></tr><tr><td>train_loss</td><td>▄▅▃▄▂▂▁▁▁▃▁▁▁▅▁▆▁▁▁▂▁▂▅▁█▁▁▁▃▁▁▃▁▁▄▁▂▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_epoch_accuracy</td><td>▁▆█</td></tr><tr><td>val_epoch_loss</td><td>█▁▅</td></tr><tr><td>val_loss</td><td>█▁▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>2</td></tr><tr><td>train_loss</td><td>0.96328</td></tr><tr><td>trainer/global_step</td><td>1499</td></tr><tr><td>val_epoch_accuracy</td><td>0.84</td></tr><tr><td>val_epoch_loss</td><td>0.58263</td></tr><tr><td>val_loss</td><td>0.58263</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">celestial-brook-8</strong> at: <a href=\"https://wandb.ai/vetka925/GPT-J_finetune_hatetweets_instruct_final/runs/pw0e5peu\" target=\"_blank\">https://wandb.ai/vetka925/GPT-J_finetune_hatetweets_instruct_final/runs/pw0e5peu</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230227_174705-pw0e5peu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pl.seed_everything(100)\n",
    "\n",
    "# logging in wandb\n",
    "WANDB_PROJECT = \"GPT-J_finetune_hatetweets_instruct_final\"\n",
    "wandb.login()\n",
    "wandb_logger = WandbLogger(project=WANDB_PROJECT)\n",
    "\n",
    "\n",
    "\n",
    "# Configuration\n",
    "config = FinetunerConfig(\n",
    "                        lr=1e-4, \n",
    "                        batch_size=2,\n",
    "                        num_epochs=3, \n",
    "                        adapter_dim=2, \n",
    "                        classification=True)\n",
    "\n",
    "\n",
    "# Choose a way to finetune\n",
    "\n",
    "# Adapters for all linear layers includding embedding\n",
    "model_post_init_func=partial(add_all_adapters, adapter_dim=config.adapter_dim)\n",
    "\n",
    "# # Adapters for attention layers\n",
    "# model_post_init_func=partial(add_attention_adapters, adapter_dim=config.adapter_dim)\n",
    "\n",
    "# # No adapters, only train model linearnorm\n",
    "# model_post_init_func=None\n",
    "\n",
    "\n",
    "\n",
    "finetuner = GPTJ8bitFineTuner(\n",
    "                                model_name=\"hivemind/gpt-j-6B-8bit\", \n",
    "                                model_post_init_func=model_post_init_func, \n",
    "                                fine_tuning_config=config, \n",
    "                                train_dataset=train_dataset,\n",
    "                                val_dataset=val_dataset)\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(   logger=wandb_logger,    \n",
    "                        log_every_n_steps=1,  \n",
    "                        gpus=-1,              \n",
    "                        max_epochs=config.num_epochs,\n",
    "                        deterministic=True,\n",
    "                        enable_checkpointing=False,\n",
    "                    )\n",
    "\n",
    "trainer.fit(finetuner)\n",
    "wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune report\n",
    "\n",
    "[WanDB Report](https://api.wandb.ai/links/vetka925/8acj071n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check model generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTJForCausalLM(\n",
       "  (transformer): GPTJModel(\n",
       "    (wte): FrozenBNBEmbedding(50400, 4096)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (16): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (17): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (18): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (19): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (20): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (21): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (22): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (23): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (24): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (25): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (26): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (27): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): FrozenBNBLinear(4096, 50400)\n",
       ")"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get trained model\n",
    "model = finetuner.model.to('cuda')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sample\n",
    "prompt = '''Classify the following messages into one of the following categories: hate, neutral, offensive\n",
    "\n",
    "Message: This is the great weather\n",
    "\n",
    "Category:'''\n",
    "\n",
    "sample = tokenizer(prompt, return_tensors='pt')\n",
    "sample = {k: v.to('cuda') for k, v in sample.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the following messages into one of the following categories: hate, neutral, offensive\n",
      "\n",
      "Message: This is the great weather\n",
      "\n",
      "Category: neutral\n"
     ]
    }
   ],
   "source": [
    "# Generate 1 token after prompt\n",
    "gen_tokens = model.generate(**sample, \n",
    "               temperature=0.2, \n",
    "               do_sample=True, \n",
    "               max_length=(sample['input_ids'].shape[-1]) + 1)\n",
    "print(tokenizer.decode(gen_tokens[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Side effects\n",
    "The instruction based finetuning has intresting effects.  \n",
    "The model has trained its attention and now it can be used for classification of unseen labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the following messages into one of the following categories: Politics, Sports, Business, Space, Tech, Social\n",
      "\n",
      "Message: Prime minister said no agreement had yet been made between the UK and the European Union.\n",
      "\n",
      "Category: Politics\n"
     ]
    }
   ],
   "source": [
    "# Let's try to detect bbc news topic\n",
    "\n",
    "prompt = '''Classify the following messages into one of the following categories: Politics, Sports, Business, Space, Tech, Social\n",
    "\n",
    "Message: Prime minister said no agreement had yet been made between the UK and the European Union.\n",
    "\n",
    "Category:'''\n",
    "\n",
    "sample = tokenizer(prompt, return_tensors='pt')\n",
    "sample = {k: v.to('cuda') for k, v in sample.items()}\n",
    "\n",
    "gen_tokens = model.generate(**sample, \n",
    "               temperature=0.2, \n",
    "               do_sample=True, \n",
    "               max_length=(sample['input_ids'].shape[-1]) + 1)\n",
    "print(tokenizer.decode(gen_tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the following messages into one of the following categories: Politics, Sports, Business, Space, Tech, Social\n",
      "\n",
      "Message: Netflix cuts prices for subscribers in more than 30 countries\n",
      "\n",
      "Category: Business\n"
     ]
    }
   ],
   "source": [
    "# Let's try to detect bbc news topic\n",
    "\n",
    "prompt = '''Classify the following messages into one of the following categories: Politics, Sports, Business, Space, Tech, Social\n",
    "\n",
    "Message: Netflix cuts prices for subscribers in more than 30 countries\n",
    "\n",
    "Category:'''\n",
    "\n",
    "sample = tokenizer(prompt, return_tensors='pt')\n",
    "sample = {k: v.to('cuda') for k, v in sample.items()}\n",
    "\n",
    "gen_tokens = model.generate(**sample, \n",
    "               temperature=0.2,\n",
    "               do_sample=False, \n",
    "               max_length=(sample['input_ids'].shape[-1]) + 1)\n",
    "print(tokenizer.decode(gen_tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the following messages into one of the following categories: Politics, Sports, Business, Space, Tech, Social\n",
      "\n",
      "Message: Real Madrid's title hopes suffered a further setback after being held by 10-man rivals Atletico Madrid at the Bernabeu.\n",
      "\n",
      "Category: Sports\n"
     ]
    }
   ],
   "source": [
    "# Let's try to detect bbc news topic\n",
    "\n",
    "prompt = '''Classify the following messages into one of the following categories: Politics, Sports, Business, Space, Tech, Social\n",
    "\n",
    "Message: Real Madrid's title hopes suffered a further setback after being held by 10-man rivals Atletico Madrid at the Bernabeu.\n",
    "\n",
    "Category:'''\n",
    "\n",
    "sample = tokenizer(prompt, return_tensors='pt')\n",
    "sample = {k: v.to('cuda') for k, v in sample.items()}\n",
    "\n",
    "gen_tokens = model.generate(**sample, \n",
    "               temperature=0.1,\n",
    "               do_sample=False, \n",
    "               max_length=(sample['input_ids'].shape[-1]) + 1)\n",
    "print(tokenizer.decode(gen_tokens[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model with adapters for all layers\n",
    "\n",
    "https://api.wandb.ai/links/vetka925/k8lpj3cn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "855cc711d80c8d878070baad7d5f36be1934899c6a0e360cd07c7a1deca02102"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
